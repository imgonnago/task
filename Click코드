import os
import random
import numpy as np
import pandas as pd
from imblearn.under_sampling import TomekLinks
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
import xgboost as xgb
from sklearn.metrics import accuracy_score
import time

_tic = None
def tic():
    global _tic
    _tic = time.perf_counter()

def toc(msg="Elapsed"):
    dt = time.perf_counter() - _tic
    print(f"{msg}: {dt:6f} s")
    return dt

#tic()
data = pd.read_csv("C:/dataset_click/train_original_v2.csv")
#toc()
train_data, test_data = train_test_split(data, test_size=0.3, random_state = 42, shuffle=True)

#tomek link사용. 이건 언더샘플링 할때 사용하는 라이브러리. 레이블 나눌때 가까운 거리로 있는 거 날리는거
tl = TomekLinks(sampling_strategy='majority')


train_data.to_csv("C:/dataset_click/train.csv",index=False)
test_data.to_csv("C:/dataset_click/test.csv",index=False)
train_df = pd.read_csv("C:/dataset_click/train.csv", nrows= 1000000)
test_df = pd.read_csv("C:/dataset_click/test.csv")


#null값이 있는 거 0으로 만듬

for col in train_df.columns:
    if train_df[col].isnull().sum() != 0:
        train_df[col].fillna(0, inplace=True)

for col in test_df.columns:
    if test_df[col].isnull().sum() != 0:
        test_df[col].fillna(0, inplace=True)

import category_encoders as ce

encoding_target = list(train_df.dtypes[train_df.dtypes == "object"].index)
enc = ce.CountEncoder(cols = encoding_target).fit(train_df)
train_df = enc.transform(train_df)
test_df = enc.transform(test_df)

corr_matrix = train_df.corr(numeric_only=True)
print(corr_matrix)

click_corr = corr_matrix['Click']
selected = click_corr[click_corr.abs() >= 0.05]
selected = pd.DataFrame(selected)
selected = selected.reset_index()
selected.columns = ['Feature','rate']
print(selected)
columns = selected["Feature"]
columns = columns.array

train_df = train_df[columns]
test_df = test_df[columns]

corr_df = train_df.drop("Click", axis =1)

for i in range(len(corr_df.columns)):
    for j in range(i + 1, len(corr_df.columns)):
        cor1 = corr_df.columns[i]
        cor2 = corr_df.columns[j]
        corr = corr_df[cor1].corr(corr_df[cor2])
        if abs(corr) < 0.8:
            continue
        print(f"{cor1} 과 {cor2}의 상관관계 : {corr}")

#1,2,5,12

#클래스의 편향, 불균형 알아보는 그래프
import plotly.express as px

click = train_df['Click'].value_counts(normalize = True)

click_figure = px.bar(click,
                      x=["Not Clicked :0", "Clicked : 1"],
                      y=click.values.tolist(),
                      labels={"x": "Value", "y": "percentage"},
                      width = 450,
                      height = 500)

click_figure.show()

#train, test _set 만들기
train_x = train_df.drop(columns = ["Click","F01","F02","F05","F12"], axis=1)
train_y = train_df["Click"]
train_y.value_counts()

test_x = test_df.drop(columns = ["Click","F01","F02","F05","F12"], axis=1)
test_y = test_df["Click"]

train_x = np.log1p(train_x)
test_x = np.log1p(test_x)

#object형 데이터들을 빈도수에 따라 숫자형으로 바꾸기


#여기서 tomek link사용
train_x, train_y = tl.fit_resample(train_x, train_y)
train_x.value_counts()

#model_fit
rf_model= RandomForestClassifier(
    n_estimators=500,
    max_depth=50,
    min_samples_split=3,
    min_samples_leaf=2,
    max_features='sqrt',
    bootstrap=True,
    random_state=42,
    n_jobs=-1,
)

tic()
rf_model.fit(train_x, train_y)
toc()

xgb_model = xgb.XGBClassifier(
    objective = 'binary:logistic',
    n_estimators=600,
    learning_rate=0.09,
    max_depth = 2,
    random_state=42,
    n_jobs=-1
)

tic()
xgb_model.fit(train_x, train_y)
toc()

hard_voter = VotingClassifier(
    estimators=[('rf', rf_model), ('xgb', xgb_model)],
    voting='hard'
)

hard_voter.fit(train_x, train_y)

final_pred = hard_voter.predict(test_x)
final_acc = accuracy_score(test_y, final_pred)

rf_train_pred = rf_model.predict(train_x)
rf_test_pred = rf_model.predict(test_x)
xgb_train_pred = xgb_model.predict(train_x)
xgb_test_pred = xgb_model.predict(test_x)

rf_train_acc = accuracy_score(train_y, rf_train_pred)
xgb_train_acc = accuracy_score(train_y, xgb_train_pred)
rf_test_acc = accuracy_score(test_y, rf_test_pred)
xgb_test_acc = accuracy_score(test_y, xgb_test_pred)
print("--------------성능 평가 지표---------------")
print(f" rf train acc: {rf_train_acc}")
print(f" rf test acc: {rf_test_acc}")
print("-------------------------------------------------")
print(f" xgb train acc: {xgb_train_acc}")
print(f" xgb test acc: {xgb_test_acc}")
print("-------------------------------------------------")
print(f" final voting: {final_acc}")
